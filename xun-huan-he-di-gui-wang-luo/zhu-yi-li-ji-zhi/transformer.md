# Transformer

## 介绍

> [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)

主要序列转导模型基于复杂的复发或卷积神经网络，其包括编码器和解码器。 性能最佳的模型还通过注意机制连接编码器和解码器。 我们提出了一种新的简单网络架构，Transformer，完全基于注意机制，完全免除重复和卷积。在两个机器翻译任务上的实验表明，这些模型在质量上更优越，同时更具并行性，并且需要大量的时间来训练。我们的模型在WMT 2014英语 - 德语翻译任务中达到了28.4 BLEU，超过现有的最佳成绩，包括2个以上的BLEU。在WMT 2014英语到法语的翻译任务中，我们的模型建立了一个新的单模型最新BLEU得分为41.8，在8个GPU上续航3.5天，这是最好的模型训练成本的一小部分文献。我们通过将其成功应用于英语选区解析大型和有限的训练数据，表明Transformer能够很好地概括其他任务。



