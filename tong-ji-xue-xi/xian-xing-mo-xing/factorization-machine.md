# Factorization Machine

## 介绍

> [Factorization Machines](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf)

本文介绍了因子分解机，这是一种结合支持向量机\(SVM\)和因子分解模型优点的新模型类。像支持向量机一样，FMs是一种通用的预测器，适用于任何实值特征向量。与SVMs不同，FMs使用因子化参数来模拟变量之间的相互作用。因此，即使在支持向量机失败的稀疏性问题\(如推荐系统\)中，他们也能够估计交互。结果表明，FMs的模型方程可以在线性时间内计算出来，从而可以直接优化FMs。因此，与非线性支持向量机不同，对偶形式的变换是不必要的，模型参数可以直接估计，而不需要解中的任何支持向量。我们展示了与支持向量机的关系以及FMs在稀疏环境下参数估计的优势。

另一方面，有许多不同的因子分解模型，如矩阵因子分解、并行因子分析或特殊模型，如奇异值分解++、PITF或FPMC。这些模型的缺点是它们不适用于一般的预测任务，而只能用于特殊的输入数据。此外，它们的建模和优化算法是针对每个任务单独导出的。我们表明，FMs可以通过指定输入数据\(即特征向量\)来模拟这些模型。这使得即使用户没有因子分解模型方面的专家知识，也可以很容易地应用因子分解模型

总的来说，我们提出的FM的优点是：

1. 支持向量机失败时，支持向量机允许在非常稀疏的数据下进行参数估计。
2.  支持向量机具有线性复杂度，可以在原模型中优化，不依赖支持向量机等支持向量。我们表明，FMs可以扩展到像Netflixwith这样的大型数据集，有1亿个训练实例。
3. FMs是一个通用的预测器，可以处理任何实值特征向量。与此相反，其他最先进的因子分解模型只对非常有限的输入数据有效。我们将展示，仅仅通过定义输入数据的特征向量，FMs就可以模仿最先进的模型，如偏置MF、SVD++、PITF或FPMC

## 方法

### Factorization Machine Model

![](../../.gitbook/assets/image%20%28195%29.png)

其中

![](../../.gitbook/assets/image%20%28160%29.png)

![](../../.gitbook/assets/image%20%2832%29.png)

#### 稀疏数据

在稀疏设置中，通常没有足够的数据来直接和独立地估计变量之间的相互作用。 即使在这些设置中，因子分解机器也可以估计交互，因为它们通过分解它们来打破交互参数的独立性。通常，这意味着一次交互的数据也有助于估计相关交互的参数。

#### 计算复杂度

![](../../.gitbook/assets/image%20%2815%29.png)

### Factorization Machines as Predictors

![](../../.gitbook/assets/image%20%28214%29.png)

### Learning Factorization Machines

![](../../.gitbook/assets/image%20%284%29.png)

### SVMs fail for very sparse problems

![](../../.gitbook/assets/image%20%2843%29.png)

考虑使用高阶核的SVM

![](../../.gitbook/assets/image%20%288%29.png)

由于训练数据的稀疏性，很多高阶的权重得不到有效训练，所以对于稀疏数据效果一般。而FM使用因子分解的形式，有效避免了参数得不到训练的情况.



