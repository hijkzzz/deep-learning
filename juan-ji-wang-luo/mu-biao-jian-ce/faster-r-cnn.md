# Faster R-CNN

## 介绍

> [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/pdf/1506.01497.pdf)

最先进的物体检测网络依赖于区域建议算法来假设物体位置。像SPPnet \[1\]和Fast R-CNN \[2\]这样的进展减少了这些检测网络的运行时间，将区域候选计算暴露为瓶颈 。在这项工作中，我们引入了一个区域提议网络（RPN），它与检测网络共享全图像卷积特征，从而实现几乎无成本的区域候选建议。RPN是一个完全卷积网络，它同时预测每个位置的对象边界和对象分数。RPN经过端到端培训，可生成高质量区域提案，Fast R-CNN用于检测。我们通过共享其卷积特征进一步将RPN和Fast R-CNN合并到一个网络中 - 使用最近流行的具有“注意”机制的神经网络术语，RPN组件告诉统一网络应该关注哪里。对于非常深的VGG-16型号\[3\]，我们的检测系统在GPU上的帧速率为5fps（包括所有步骤），同时在PASCAL VOC 2007,2012和MS上实现了最先进的物体检测准确度。 COCO数据集，每个图像仅用300个候选。在ILSVRC和COCO2015比赛中，Faster R-CNN和RPN是几个赛道中获得第一名的参赛者的基础。

## 方法

![](../../.gitbook/assets/image%20%2875%29.png)

我们的物体检测系统称为Faster R-CNN，由两个模块组成。第一个模块是产生候选区域的深度卷积网络，第二个模块是使用候选区域的Fast R-CNN检测器\[2\]。如图2所示，整个系统使用一个统一的目标检测网络。使用最近流行的神经网络术语和“注意”\[31\]机制，RPN模块告诉Fast R-CNN模块应该关注哪里。

### RoI pooling

在Fast R-CNN中，RoI池化使候选框内的特征映射到固定大小的特征图。主要原理是利用空间金字塔池化，把任意大小的窗口划分成 $$k$$ 个多个 $$n_k*n_k$$的特征图，对每个 $$1*1$$ 方块里面的特征进行池化。 最后将不同的特征合并到一起。

![](../../.gitbook/assets/image%20%2856%29.png)

### Region Proposal Networks

如图3所示，区域建议网络\( RPN \)将图像\(任何大小\)作为输入，并输出一组矩形主题建议，每个建议都有一个对象分数。为了生成区域提议，我们在最后一个共享卷积层输出的卷积特征映射上滑动一个小网络。

![](../../.gitbook/assets/image%20%2820%29.png)

#### Anchors

在每个滑动窗口位置，我们同时预测多个候选区域提案，其中每个位置的最大可能提议的数量 $$k$$ 被指定。这些大小形状不同的区域就是Anchors。可以对数据集进行聚类得到。

#### Translation-Invariant Anchors

我们方法的一个重要特性是，无论是anchors还是关于anchors计算候选区域的函数，它都是平移不变的。如果平移图像中的一个对象，则候选建议也应该平移，并且相同的函数应该能够在任一位置预测建议。我们的方法保证了这种平移不变性。

#### Loss Function

损失函数分为分类损失和回归损失

![](../../.gitbook/assets/image%20%2880%29.png)

对于分类损失，与anchor的 $$IoU$$ 最高的为正样本， $$IoU<0.3$$ 的为负样本， $$\mathcal{p}_{i}^{*}$$ 表示当前anchor是否存在对象。这两个项由 $$N_{cls}$$ 和 $$N_{reg}$$ 归一化，并由平衡参数 $$λ$$ 加权。 在我们的当前实现中（如在已发布的代码中），分类项通过mini-batchsize（即$$N_{cls}$$ = 256）进行归一化，并且通过锚点位置的数量（即$$N_{reg}$$~2,400）对其进行归一化。 默认我们设置 $$λ= 10$$ 。

预测边框的坐标计算方法如下：

![](../../.gitbook/assets/image%20%2879%29.png)

其中$$x, y, w, h$$ 分别表示边框的中心坐标、宽和高。，$$a$$ 表示为anchor的中心坐标、宽、高。即预测的值是一个偏移量。

#### Training RPN

优化所有锚点的损失函数，但这样做会偏向负样本，因为它们占主导地位。相反，我们在图像中随机抽样256个锚点来计算小批量的损失函数，其中采样的正负锚点的比例为1：1。 如果图像中的正样本数少于128个，我们将小批次用负类填充。

我们通过从标准偏差为0.01的零均值高斯分布中抽取8来随机初始化所有新层。所有其他层\(即共享卷积层\)都是通过预先训练图像网分类的模型来初始化的。

### Sharing Features for RPN and Fast R-CNN

#### Alternating training

在这个解决方案中，我们首先训练RPN，并使用提议来训练快速R-CNN。然后使用由快速R-CNN调谐的网络来初始化RPN，并且该过程被迭代。 这是本文所有实验中使用的解决方案。

#### Approximate joint training

在此解决方案中，RPN和Fast R-CNN网络在训练期间合并为一个网络，如图2所示。在每个SGD迭代中，正向传递产生区域建议，当训练Fast R-CNN时，它们被视为固定的，预先计算的建议。  反向传播如常进行，其中共享层将来自RPN损失和Fast R-CNN损耗的反向传播信号组合。 该解决方案易于实施。 但是这个解决方案忽略了建议的坐标的导数也是网络响应，因此是近似值。

#### Non-approximate joint training

如上所述，RPN预测的边界框也是输入的函数。 快速R-CNN中的RoI池化层\[2\]接受卷积特征以及预测的边界框作为输入，因此理论上有效的反向传播求解器也应该涉及梯度关于框坐标。在上述近似的联合训练中忽略了这些梯度。 在非近似联合训练解决方案中，我们需要一个关于框坐标可微分的RoI池化层。 这是一个非常重要的问题，可以通过\[15\]中开发的“RoI Wraping"给出解决方案，这超出了本文的范围。

#### 4-Step Alternating Training

在本文中，我们采用实用的4步训练算法来通过交替优化来学习共享特征。在第一步中，我们按照上一节的描述训练RPN。 该网络使用ImageNet预先训练的模型进行初始化，并针对区域提出的任务进行端对端微调。在第二步中，我们使用由步骤1 RPN生成的提议通过Fast R-CNN训练单独的检测网络。该检测网络也由ImageNet预先训练的模型初始化。此时，两个网络不共享卷积层。在第三步中，我们使用检测器网络来初始化RPN训练，但是我们固定共享卷积层，只修改RPN特有的层。现在这两个网络共享卷积层。最后，保持共享卷积层固定，我们微调快速R-CNN的独特层。这样，两个网络共享相同的卷积层并形成统一的网络。 类似的交替训练可以进行更多的迭代，但我们观察到可忽略不计的改进。

## 测试

![](../../.gitbook/assets/image%20%2869%29.png)







