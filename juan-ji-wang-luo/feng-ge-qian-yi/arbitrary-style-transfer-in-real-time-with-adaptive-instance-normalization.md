# Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization

> [Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization](https://arxiv.org/abs/1703.06868)

Gatys等人最近引入了一种神经算法，以另一幅图像的风格渲染内容图像，实现所谓的风格转换。然而，他们的框架需要一个缓慢的迭代优化过程，这限制了它的实际应用。已经提出了具有前馈神经网络的近似值以加速神经类型转移。不幸的是，速度提升需要付出代价：网络通常与固定的样式相关联，并且无法适应任意新的样式。 在本文中，我们提出了一种简单而有效的方法，它首次实现了任意样式传输。我们方法的核心是一个新颖的自适应实例规范化（AdaIN）层，它将内容特征的均值和方差与样式特征的均值和方差对齐。我们的方法实现了与现有最快方法相当的速度，而没有对预定义样式集的限制。另外，我们的方法允许灵活的用户控制，例如内容式权衡，样式插值，颜色和空间控制，所有这些都使用单个前馈神经网络。

## 方法

### Instance Normalization

![](../../.gitbook/assets/image%20%2847%29.png)

与BN层不同，这里 $$μ(x)$$ 和 $$σ(x)$$ 在每个样本的每个通道上独立地跨空间维度进行计算：

![](../../.gitbook/assets/image%20%28112%29.png)

![](../../.gitbook/assets/image%20%28111%29.png)

### Conditional Instance Normalization

Dumoulinet提出了一种条件实例正则化（CIN）层，它为每种样式 $$s$$ 学习一组不同的参数$$\gamma^s$$ 和 $$\beta^s$$ ，而不是只学习一组仿射参数 $$\gamma$$ 和 $$\beta$$ 。令人惊讶的是，网络可以通过使用相同的卷积参数生成不完全不同风格的图像但IN层中的不同参数。

![](../../.gitbook/assets/image%20%28175%29.png)

与没有归一化层的网络相比，具有CIN层的网络需要 $$2FS$$ 个附加参数，其中 $$F$$ 是网络中特征图的总数。由于附加参数的数量与样式的数量成线性比例，因此扩展它们的方法来对大量样式\(例如数万个\)建模是一个挑战。此外，如果不重新训练网络，他们的方法无法适应新的风格。

### Interpreting Instance Normalization

尽管\(条件\)实例规范化取得了巨大的成功，但它们在样式转换方面特别有效的原因仍然难以解释。Ulyanov认为IN的成功在于其对图像对比度的不变性。然而，IN发生在特征空间中，因此它应该比像素空间中的简单对比度归一化具有更深刻的影响。 也许更令人惊讶的是，IN中的仿射参数完全改变了输出图像的样式。

众所周知，DNN的卷积特征统计可以捕捉图像\[的风格。而盖特·艾尔使用二阶统计量作为它们的优化目标。最近显示，与许多其他统计数据相匹配，包括channel-wise mean和variance，对于风格转换也是有效的。通过这些观察得出的结论，我们认为实例正规化通过对特征统计进行正规化来实现一种风格规范化，即均值和方差。尽管DNN是图像描述者，但我们相信网络的特征统计可以控制生成图像的风格。

我们进行了以下实验：即测试对比度归一化和风格归一化后IN的影响力，结果表明IN在风格化归一化后效果变差，所以也说明了IN本身的作用就是风格归一化。

![](../../.gitbook/assets/image%20%2838%29.png)

### Adaptive Instance Normalization

如果IN将输入规范化为仿射参数指定的单一样式，是否可以通过使用自适应仿射变换使其适应任意的样式？ 在这里，我们提出了一个简单的IN扩展，我们称之为adaptive实例规范化（AdaIN）。AdaIN接收内容输入x和样式输入y，并简单地将x的通道均值和方差对齐以匹配y。与BN，IN或CIN不同，AdaIN没有可学习的仿射参数。相反，它从样式输入中自适应地计算仿射参数。

![](../../.gitbook/assets/image%20%2853%29.png)

直观地说，让我们考虑一个检测特定风格的画笔笔迹的特征通道。具有这种笔画的样式图像将为该特征产生高平均激活。AdaIN生成的输出将具有相同的高平均激活功能，同时保留内容图像的空间结构。笔画特征可以通过前馈解码器转换到图像空间，此通道的方差可以编码更细微的样式信息，也可以转移到AdaIN输出和最终输出图像。

简而言之，AdaIN通过传递特征统计数据，特别是通道均值和方差，在特征空间中执行样式传递。

### Experimental Setup

![](../../.gitbook/assets/image%20%28229%29.png)

#### Loss Function

整体损失氛围内容损失和风格损失

![](../../.gitbook/assets/image%20%2883%29.png)

内容损失是目标特征和输出图像特征之间的欧几里德距离。我们使用AdaIN输出内容目标，而不是常用的内容图像的特征响应。我们发现这导致了稍微更快的收敛，并且没有反转AdaIN输出的目标

![](../../.gitbook/assets/image%20%2822%29.png)

由于我们的AdaIN图层仅传递样式特征的均值和标准偏差，因此我们的样式丢失仅匹配这些统计信息。虽然我们发现常用的Gram矩阵损失可以产生类似的结果，但我们对IN统计数据进行了匹配，因为它在概念上更清晰：

![](../../.gitbook/assets/image%20%28202%29.png)

其中每个φ标识VGG-19中的一层，用于计算样式损失

## 效果

![](../../.gitbook/assets/image%20%28155%29.png)

