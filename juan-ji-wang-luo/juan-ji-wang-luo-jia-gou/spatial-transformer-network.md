# Spatial transformer network

## 介绍

> [Spatial transformer network](http://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf)

卷积神经网络定义了一类异常强大的模型，但是仍然受到缺乏以计算和参数有效的方式对输入数据保持空间不变的能力的限制。在这项工作中，我们引入了一个新的可学习模块——空间转换器，它明确允许对网络中的数据进行空间处理。这种可微分模块可以被引入到现有的卷积结构中，使神经网络能够根据特征映射本身主动地对特征映射进行空间变换，而无需对优化过程进行任何额外的训练监督或修改。我们表明，空间转换器的使用导致模型学习平移、缩放、旋转和更一般的翘曲的不变性，结果在几个基准上的最先进的性能，并为一些类的转换。

![](../../.gitbook/assets/image%20%2867%29.png)

空间变形器可以被合并到CNNs中，以完成多种多样的任务，例如:\(i\)图像分类:假设训练一个CNN，根据图像是否包含一个特定的数字，该数字的位置和大小可能会随着每个样本的不同而显著变化\(且与类无关\)，对图像进行多路分类;将适当区域裁剪出来并按比例归一化的空间变压器，可以简化后续的分类任务，分类性能优越，如图1所示。（ii）共定位：给定一组包含相同（但未知）类的不同实例的图像，可以使用空间变换器在每个图像中对它们进行定位; （iii）空间注意：空间变换器可以用于需要注意机制的空间，例如在\[11,29\]中，但是更灵活并且可以在没有强化学习的情况下用反向传播进行训练。 使用注意力的一个主要好处是，可以使用转换（以及如此关注），较低分辨率的输入以支持更高分辨率的输入，从而提高计算效率。

## 方法

![](../../.gitbook/assets/image%20%2836%29.png)

### Localisation Network

定位网络拟合一个变换 $$\mathcal{T}_{\theta}$$ 的参数 $$\theta$$ ，如对于仿射变换 $$θ$$ 是6维的。

$$
\theta=f_{\mathrm{loc}}(U)
$$

### Parameterised Sampling Grid

为了执行输入特征映射的变形，通过应用以输入特征映射中的特定位置为中心的采样核算来计算每个输出像素（这将在下一节中完整地描述）。

一般来说，输出像素被定义为位于规则网格上 $$G=\left\{G_{i}\right\}, \ G_{i}=\left(x_{i}^{t}, y_{i}^{t}\right)$$ 

![](../../.gitbook/assets/image%20%28156%29.png)

$$\left(x_{i}^{t}, y_{i}^{t}\right)$$ 输出特征图中规则网格的目标坐标， $$\left(x_{i}^{s}, y_{i}^{s}\right)$$ 是输入特征图中定义采样点的源坐标， $$\mathrm{A}_{\theta}$$ 是仿射变换矩阵。

（1）中定义的变换允许将裁剪，平移，旋转，缩放和倾斜应用于输入特征图，并且仅需要由定位网络产生6个参数（Aθ的6个元素）。

![](../../.gitbook/assets/image%20%2874%29.png)

![](../../.gitbook/assets/image%20%2899%29.png)

### Differentiable Image Sampling

得到转换后的坐标，接下来用新坐标 $$\left(x_{t}^{t}, y_{i}^{t}\right)$$ 插值生成输出特征图：

![](../../.gitbook/assets/image%20%28100%29.png)

其中$$k(x)$$ 表示插值函数（如双线性插值）， $$U_{n m}^{c}$$ 是输入特征通道C位置为 $$(n, m)$$ 元素值， $$V_{i}^{c}$$ 是输出值。请注意，对于输入的每个通道，采样是完全相同的，因此每个通道都以相同的方式进行转换（这保留了通道之间的空间一致性）。

双线性插值可表示为

![](../../.gitbook/assets/image%20%2848%29.png)

其对应的偏导数为

![](../../.gitbook/assets/image%20%28123%29.png)

### Spatial Transformer Networks

定位网络，网格生成器和采样器的组合形成空间变换器（图2）。 这是一个独立的模块，可以在任何时候放入CNN架构，并且可以任意数量，从而产生互联空间变换器。 该模块在计算上非常快并且不会削弱训练速度，在简单地使用时导致非常小的时间开销，由于随后的下采样可以应用于变压器的输出，因此在注意模型中存在潜在的加速。

## 实验

![](../../.gitbook/assets/image%20%28139%29.png)

